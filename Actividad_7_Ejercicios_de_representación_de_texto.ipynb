{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSh5eZv1GRTOVnk+MdUEA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErikaDenisse29/ColabFiles/blob/main/Actividad_7_Ejercicios_de_representaci%C3%B3n_de_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Maestría en Inteligencia Artificial y Analítica de Datos**\n",
        "\n",
        "Procesamiento de Lenguaje Natural\n",
        "\n",
        "Actividad 7: Ejercicios de representación de texto.\n",
        "\n"
      ],
      "metadata": {
        "id": "B-lqEbKP_NBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "D5EntpMr8RQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importación de librerías**"
      ],
      "metadata": {
        "id": "EjIlzJiI9BDT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fp87tfqi78eB"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "corpus_es = [\n",
        "    \"Me encantó la película, los actores fueron increíbles\",\n",
        "    \"No me gustó la película, el guion fue muy malo\",\n",
        "    \"La actuación fue excelente, pero la historia era predecible\",\n",
        "    \"Película aburrida, me dormí a la mitad\",\n",
        "    \"¡Maravillosa! Recomiendo esta película a todos mis amigos\",\n",
        "    \"El guion estaba mal escrito, pero la actuación salvó la película\",\n",
        "    \"Demasiado larga y lenta, no la volvería a ver\",\n",
        "    \"Me gustó mucho, los efectos especiales fueron impresionantes\",\n",
        "    \"No es mala, pero esperaba algo más emocionante\",\n",
        "    \"Una obra maestra del cine español, increíble dirección\",\n",
        "    \"El final fue confuso, no entendí nada\",\n",
        "    \"Excelente cinematografía, pero el guion flojo\",\n",
        "    \"Demasiado predecible, ya sabía lo que iba a pasar\",\n",
        "    \"Me reí mucho, muy divertida y entretenida\",\n",
        "    \"La música fue espectacular, pero los actores no convencieron\",\n",
        "    \"Película mediocre, no aporta nada nuevo\",\n",
        "    \"Excelente historia, emocionante hasta el final\",\n",
        "    \"No me gustó la ambientación, parecía de bajo presupuesto\",\n",
        "    \"Muy buena dirección y fotografía, la recomiendo\",\n",
        "    \"El guion tenía agujeros, pero los efectos visuales impresionan\",\n",
        "    \"Aburrida, diálogo poco natural\",\n",
        "    \"Gran actuación de los protagonistas, realmente me impactó\",\n",
        "    \"El ritmo es lento, pero la historia es interesante\",\n",
        "    \"No la recomiendo, desperdicié mi tiempo\",\n",
        "    \"Un clásico moderno, me encantó cada escena\",\n",
        "    \"Las escenas de acción fueron espectaculares\",\n",
        "    \"El humor es pobre y los personajes poco creíbles\",\n",
        "    \"Me emocioné, la historia me llegó al corazón\",\n",
        "    \"La trama es confusa y difícil de seguir\",\n",
        "    \"Película fantástica, muy bien lograda\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 1:**\n",
        "\n",
        "Utiliza el texto crudo (sin procesar)\n",
        "\n",
        "\n",
        "\n",
        "*   Crear un CountVectorizer y un TfidfVectorizer.\n",
        "*   Aplícalos al corpus y transformar los textos.\n",
        "\n",
        "Mostrar:\n",
        "*   Dimensiones de la matriz resultante.\n",
        "*   Primeros 10 tokens y sus índices."
      ],
      "metadata": {
        "id": "A2IEGfEs9Hgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "X_count = count_vectorizer.fit_transform(corpus_es)\n",
        "\n",
        "print(\"===VECTORIZER===\")\n",
        "print(f\"Dimensiones de matriz: {X_count.shape}\")\n",
        "print(f\"Número de documentos: {X_count.shape[0]}\")\n",
        "print(f\"Número de tokens únicos: {X_count.shape[1]}\")\n",
        "print(f\"Matriz dispersa (sparse matrix): {type(X_count)}\")\n",
        "\n",
        "\n",
        "feature_names = count_vectorizer.get_feature_names_out()\n",
        "print(\"\\nPrimeros 10 tokens y sus índices:\")\n",
        "for i, token in enumerate(feature_names[:10]):\n",
        "    print(f\"Índice {i}: '{token}'\")\n",
        "\n",
        "print(f\"\\nTotal de tokens: {len(feature_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut488yOR7-f6",
        "outputId": "1c8ac9be-c1ea-4e42-f5eb-653529a1809a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===VECTORIZER ===\n",
            "Dimensiones de matriz: (30, 127)\n",
            "Número de documentos: 30\n",
            "Número de tokens únicos: 127\n",
            "Matriz dispersa (sparse matrix): <class 'scipy.sparse._csr.csr_matrix'>\n",
            "\n",
            "Primeros 10 tokens y sus índices:\n",
            "Índice 0: 'aburrida'\n",
            "Índice 1: 'acción'\n",
            "Índice 2: 'actores'\n",
            "Índice 3: 'actuación'\n",
            "Índice 4: 'agujeros'\n",
            "Índice 5: 'al'\n",
            "Índice 6: 'algo'\n",
            "Índice 7: 'ambientación'\n",
            "Índice 8: 'amigos'\n",
            "Índice 9: 'aporta'\n",
            "\n",
            "Total de tokens: 127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF Vectorizer**"
      ],
      "metadata": {
        "id": "DbLVCWni9MsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(corpus_es)\n",
        "\n",
        "print(\"===TF-IDF VECTORIZER===\")\n",
        "print(f\"Dimensiones de matriz: {X_tfidf.shape}\")\n",
        "print(f\"Número de documentos: {X_tfidf.shape[0]}\")\n",
        "print(f\"Número de tokens únicos: {X_tfidf.shape[1]}\")\n",
        "print(f\"Matriz dispersa (sparse matrix): {type(X_tfidf)}\")\n",
        "\n",
        "feature_names_tfidf = tfidf_vectorizer.get_feature_names_out()\n",
        "print(\"\\nPrimeros 10 tokens y sus índices:\")\n",
        "for i, token in enumerate(feature_names_tfidf[:10]):\n",
        "    print(f\"Índice {i}: '{token}'\")\n",
        "\n",
        "print(f\"\\nTotal de tokens: {len(feature_names_tfidf)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9E6ohAh8nfI",
        "outputId": "56cbce46-5575-4157-ed19-41c6c222e123"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TF-IDF VECTORIZER ===\n",
            "Dimensiones de matriz: (30, 127)\n",
            "Número de documentos: 30\n",
            "Número de tokens únicos: 127\n",
            "Matriz dispersa (sparse matrix): <class 'scipy.sparse._csr.csr_matrix'>\n",
            "\n",
            "Primeros 10 tokens y sus índices:\n",
            "Índice 0: 'aburrida'\n",
            "Índice 1: 'acción'\n",
            "Índice 2: 'actores'\n",
            "Índice 3: 'actuación'\n",
            "Índice 4: 'agujeros'\n",
            "Índice 5: 'al'\n",
            "Índice 6: 'algo'\n",
            "Índice 7: 'ambientación'\n",
            "Índice 8: 'amigos'\n",
            "Índice 9: 'aporta'\n",
            "\n",
            "Total de tokens: 127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparar las diferencias entre ambas matrices (CountVectorizer y TfidfVectorizer), mencionando de manera general las diferencias observadas.\n",
        "\n",
        "Las diferencias que observe fueron:\n",
        "\n",
        "CountVectorizer usa frecuencias enteras, TF-IDF usa pesos decimales\n",
        "\n",
        "TF-IDF reduce el peso de palabras comunes y aumenta el de palabras relevantes\n",
        "\n",
        "TF-IDF automáticamente da menos importancia a palabras muy frecuentes\n",
        "\n",
        "TF-IDF normaliza los valores, CountVectorizer no"
      ],
      "metadata": {
        "id": "1RVuxAcg9UY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"===COMPARACIÓN DE VALORES ===\")\n",
        "print(\"Comparación para algunos términos:\")\n",
        "\n",
        "print(f\"Mismos tokens en ambos vectorizadores: {np.array_equal(feature_names, feature_names_tfidf)}\")\n",
        "sample_tokens = ['película', 'guion', 'excelente', 'aburrida']\n",
        "\n",
        "for token in sample_tokens:\n",
        "    if token in feature_names:\n",
        "        idx = np.where(feature_names == token)[0][0]\n",
        "        count_vals = X_count[:, idx].toarray().flatten()\n",
        "        tfidf_vals = X_tfidf[:, idx].toarray().flatten()\n",
        "\n",
        "        print(f\"\\nToken: '{token}' (índice {idx})\")\n",
        "        print(f\"Count values: {count_vals}\")\n",
        "        print(f\"TF-IDF values: {[f'{x:.3f}' for x in tfidf_vals]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_obKL2oo80po",
        "outputId": "cccf2eb1-2738-4324-d82c-8346b893ed9c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===COMPARACIÓN DE VALORES ===\n",
            "Comparación para algunos términos:\n",
            "Mismos tokens en ambos vectorizadores: True\n",
            "\n",
            "Token: 'película' (índice 101)\n",
            "Count values: [1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "TF-IDF values: ['0.292', '0.280', '0.000', '0.325', '0.256', '0.233', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.295', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.316']\n",
            "\n",
            "Token: 'guion' (índice 58)\n",
            "Count values: [0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "TF-IDF values: ['0.000', '0.336', '0.000', '0.000', '0.000', '0.279', '0.000', '0.000', '0.000', '0.000', '0.000', '0.378', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.295', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000']\n",
            "\n",
            "Token: 'excelente' (índice 50)\n",
            "Count values: [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "TF-IDF values: ['0.000', '0.000', '0.345', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.408', '0.000', '0.000', '0.000', '0.000', '0.398', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000']\n",
            "\n",
            "Token: 'aburrida' (índice 0)\n",
            "Count values: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "TF-IDF values: ['0.000', '0.000', '0.000', '0.461', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.471', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 2: Preprocesa el texto eliminando los acentos y stopwords, así como convirtiéndolo a minúsculas.**\n",
        "\n",
        "\n",
        "*   Realiza las mismas actividades que en el ejercicio anterior.\n",
        "*   Compara las matrices del ejercicio anterior con las matrices que obtuviste en este ejercicio, mencionando de manera general las diferencias observadas.\n",
        "\n"
      ],
      "metadata": {
        "id": "ALMoaweGB6Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import numpy as np\n",
        "import re\n",
        "from unicodedata import normalize\n",
        "\n",
        "def eliminar_acentos(texto):\n",
        "    texto = normalize('NFD', texto)\n",
        "    texto = texto.encode('ascii', 'ignore')\n",
        "    texto = texto.decode(\"utf-8\")\n",
        "    return texto\n",
        "\n",
        "stopwords_es = [\n",
        "    'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las',\n",
        "    'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como',\n",
        "    'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque',\n",
        "    'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me',\n",
        "    'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante',\n",
        "    'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante',\n",
        "    'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo',\n",
        "    'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho',\n",
        "    'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas',\n",
        "    'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu',\n",
        "    'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía',\n",
        "    'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya',\n",
        "    'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras',\n",
        "    'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy',\n",
        "    'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos',\n",
        "    'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis',\n",
        "    'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían',\n",
        "    'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve',\n",
        "    'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera',\n",
        "    'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese',\n",
        "    'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando',\n",
        "    'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha',\n",
        "    'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan',\n",
        "    'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría',\n",
        "    'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías',\n",
        "    'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos',\n",
        "    'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais',\n",
        "    'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen',\n",
        "    'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres',\n",
        "    'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean',\n",
        "    'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías',\n",
        "    'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran',\n",
        "    'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras',\n",
        "    'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis',\n",
        "    'fuesen', 'siendo', 'sido', 'sed', 'tengo', 'tienes', 'tiene', 'tenemos',\n",
        "    'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan',\n",
        "    'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán',\n",
        "    'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía',\n",
        "    'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo',\n",
        "    'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos',\n",
        "    'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis',\n",
        "    'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened'\n",
        "]\n",
        "\n",
        "\n",
        "corpus_preprocesado = []\n",
        "for texto in corpus_es:\n",
        "\n",
        "    texto = texto.lower()\n",
        "    texto = eliminar_acentos(texto)\n",
        "    texto = re.sub(r'[^\\w\\s]', ' ', texto)\n",
        "    palabras = texto.split()\n",
        "    palabras_filtradas = [palabra for palabra in palabras if palabra not in stopwords_es and len(palabra) > 2]\n",
        "    texto_preprocesado = ' '.join(palabras_filtradas)\n",
        "    corpus_preprocesado.append(texto_preprocesado)\n",
        "\n",
        "print(\"=== EJEMPLOS PRE-PROCESAMIENTO ===\")\n",
        "print(\"Original:\", corpus_es[0])\n",
        "print(\"Preprocesado:\", corpus_preprocesado[0])\n",
        "print(\"\\nOriginal:\", corpus_es[1])\n",
        "print(\"Preprocesado:\", corpus_preprocesado[1])\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "print(\"===VECTORIZER (PREPROCESADO) ===\")\n",
        "count_vectorizer_prep = CountVectorizer()\n",
        "X_count_prep = count_vectorizer_prep.fit_transform(corpus_preprocesado)\n",
        "print(f\"Dimensiones de la matriz: {X_count_prep.shape}\")\n",
        "print(f\"Matriz dispersa: {type(X_count_prep)}\")\n",
        "\n",
        "feature_names_prep = count_vectorizer_prep.get_feature_names_out()\n",
        "print(f\"\\nTotal de tokens: {len(feature_names_prep)}\")\n",
        "print(\"Primeros 15 tokens y sus índices:\")\n",
        "for i, token in enumerate(feature_names_prep[:15]):\n",
        "    print(f\"Índice {i}: '{token}'\")\n",
        "\n",
        "\n",
        "print(\"\\n\\n=== TF-IDF VECTORIZER (PREPROCESADO) ===\")\n",
        "tfidf_vectorizer_prep = TfidfVectorizer()\n",
        "X_tfidf_prep = tfidf_vectorizer_prep.fit_transform(corpus_preprocesado)\n",
        "print(f\"Dimensiones de la matriz: {X_tfidf_prep.shape}\")\n",
        "print(f\"Matriz dispersa: {type(X_tfidf_prep)}\")\n",
        "\n",
        "feature_names_tfidf_prep = tfidf_vectorizer_prep.get_feature_names_out()\n",
        "print(f\"\\nTotal de tokens: {len(feature_names_tfidf_prep)}\")\n",
        "print(\"Primeros 15 tokens y sus índices:\")\n",
        "for i, token in enumerate(feature_names_tfidf_prep[:15]):\n",
        "    print(f\"Índice {i}: '{token}'\")\n",
        "\n",
        "\n",
        "print(\"\\n\\n===COMPARACIÓN CON EJERCICIO ANTERIOR ===\")\n",
        "print(\"ANTES (sin preprocesamiento):\")\n",
        "print(\"- Dimensiones: (30, 144)\")\n",
        "print(\"- Tokens incluía stopwords, acentos, puntuación\")\n",
        "print(\"- Ejemplos: 'la', 'el', 'me', 'fue', 'pero'\")\n",
        "\n",
        "print(\"\\nAHORA (con preprocesamiento):\")\n",
        "print(f\"- Dimensiones: {X_count_prep.shape}\")\n",
        "print(f\"- Tokens reducidos: {len(feature_names_prep)} vs 144\")\n",
        "print(\"- Sin stopwords, acentos, ni puntuación\")\n",
        "print(\"- Ejemplos: 'pelicula', 'actores', 'increibles', 'guion', 'excelente'\")\n",
        "\n",
        "print(f\"\\nReducción de dimensionalidad: {144} → {len(feature_names_prep)} tokens\")\n",
        "print(f\"Reducción del {((144 - len(feature_names_prep)) / 144 * 100):.1f}%\")\n",
        "\n",
        "\n",
        "print(\"\\n=== TOKENS ELIMINADOS ===\")\n",
        "print(\"Stopwords eliminadas:\", [word for word in ['la', 'el', 'me', 'fue', 'pero'] if word in stopwords_es])\n",
        "print(\"Palabras muy cortas eliminadas: palabras de 1-2 letras\")\n",
        "print(\"Acentos normalizados: 'película' → 'pelicula', 'actuación' → 'actuacion'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRPUX2UbCEa5",
        "outputId": "9aeb3cf5-ba27-4210-b85c-9b3fc3d80cdb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== EJEMPLOS PRE-PROCESAMIENTO ===\n",
            "Original: Me encantó la película, los actores fueron increíbles\n",
            "Preprocesado: encanto pelicula actores increibles\n",
            "\n",
            "Original: No me gustó la película, el guion fue muy malo\n",
            "Preprocesado: gusto pelicula guion malo\n",
            "\n",
            "==================================================\n",
            "\n",
            "===VECTORIZER (PREPROCESADO) ===\n",
            "Dimensiones de la matriz: (30, 97)\n",
            "Matriz dispersa: <class 'scipy.sparse._csr.csr_matrix'>\n",
            "\n",
            "Total de tokens: 97\n",
            "Primeros 15 tokens y sus índices:\n",
            "Índice 0: 'aburrida'\n",
            "Índice 1: 'accion'\n",
            "Índice 2: 'actores'\n",
            "Índice 3: 'actuacion'\n",
            "Índice 4: 'agujeros'\n",
            "Índice 5: 'ambientacion'\n",
            "Índice 6: 'amigos'\n",
            "Índice 7: 'aporta'\n",
            "Índice 8: 'bajo'\n",
            "Índice 9: 'bien'\n",
            "Índice 10: 'buena'\n",
            "Índice 11: 'cada'\n",
            "Índice 12: 'cine'\n",
            "Índice 13: 'cinematografia'\n",
            "Índice 14: 'clasico'\n",
            "\n",
            "\n",
            "=== TF-IDF VECTORIZER (PREPROCESADO) ===\n",
            "Dimensiones de la matriz: (30, 97)\n",
            "Matriz dispersa: <class 'scipy.sparse._csr.csr_matrix'>\n",
            "\n",
            "Total de tokens: 97\n",
            "Primeros 15 tokens y sus índices:\n",
            "Índice 0: 'aburrida'\n",
            "Índice 1: 'accion'\n",
            "Índice 2: 'actores'\n",
            "Índice 3: 'actuacion'\n",
            "Índice 4: 'agujeros'\n",
            "Índice 5: 'ambientacion'\n",
            "Índice 6: 'amigos'\n",
            "Índice 7: 'aporta'\n",
            "Índice 8: 'bajo'\n",
            "Índice 9: 'bien'\n",
            "Índice 10: 'buena'\n",
            "Índice 11: 'cada'\n",
            "Índice 12: 'cine'\n",
            "Índice 13: 'cinematografia'\n",
            "Índice 14: 'clasico'\n",
            "\n",
            "\n",
            "===COMPARACIÓN CON EJERCICIO ANTERIOR ===\n",
            "ANTES (sin preprocesamiento):\n",
            "- Dimensiones: (30, 144)\n",
            "- Tokens incluía stopwords, acentos, puntuación\n",
            "- Ejemplos: 'la', 'el', 'me', 'fue', 'pero'\n",
            "\n",
            "AHORA (con preprocesamiento):\n",
            "- Dimensiones: (30, 97)\n",
            "- Tokens reducidos: 97 vs 144\n",
            "- Sin stopwords, acentos, ni puntuación\n",
            "- Ejemplos: 'pelicula', 'actores', 'increibles', 'guion', 'excelente'\n",
            "\n",
            "Reducción de dimensionalidad: 144 → 97 tokens\n",
            "Reducción del 32.6%\n",
            "\n",
            "=== TOKENS ELIMINADOS ===\n",
            "Stopwords eliminadas: ['la', 'el', 'me', 'fue', 'pero']\n",
            "Palabras muy cortas eliminadas: palabras de 1-2 letras\n",
            "Acentos normalizados: 'película' → 'pelicula', 'actuación' → 'actuacion'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultados diferencias observadas:**\n",
        "\n",
        "Diferencias principales:\n",
        "\n",
        "Se redujo de dimensionalidad:\n",
        "\n",
        "\n",
        "*   Antes: 144 tokens\n",
        "*   Después: 97 tokens\n",
        "\n",
        "\n",
        "\n",
        "Mejor calidad de tokens:\n",
        "\n",
        "\n",
        "*   Antes: Incluía stopwords ('la', 'el', 'me'), palabras con acentos como ('película')\n",
        "*   Después: Solo palabras significativas, sin acentos, sin stopwords\n",
        "\n",
        "\n",
        "Tokens más relevantes:\n",
        "\n",
        "\n",
        "*   Mejores representaciones: 'pelicula', 'actores', 'guion', 'excelente', 'aburrida'\n",
        "\n",
        "\n",
        "**Ventajas del preprocesamiento:**\n",
        "\n",
        "\n",
        "\n",
        "*   Mejor calidad de características\n",
        "*   Menos ruido en los datos\n",
        "*   Modelos de machine learning más eficientes\n",
        "\n",
        "\n",
        "**Ejemplos:**\n",
        "\n",
        "\n",
        "\n",
        "*   \"Me encantó la película\" → \"encanto pelicula\"\n",
        "*   \"No me gustó la película\" → \"gusto pelicula\"\n",
        "\n",
        "\n",
        "El preprocesamiento elimina el ruido textual y se enfoca en las palabras que realmente aportan significado al contenido.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bC8Rh2eJCWtd"
      }
    }
  ]
}